{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n",
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1887 - accuracy: 0.9399\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0626 - accuracy: 0.9812\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0451 - accuracy: 0.9858\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0359 - accuracy: 0.9889\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 49us/sample - loss: 0.0297 - accuracy: 0.9908\n",
      "10000/10000 [==============================] - 1s 55us/sample - loss: 0.0289 - accuracy: 0.9904\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "n_input1 = 28 # pixels of a digit in MNIST\n",
    "n_input2 = n_input1 * 2 \n",
    "n_kernel = 3 # CNN with a kernel of 3 by 3 \n",
    "n_pool = 2 # CNN with a pooling of 2 by 2\n",
    "n_output = 10 # corresponds to the 10 digits (0-9)\n",
    "n_batch_size = 50 \n",
    "n_epochs = 5\n",
    "\n",
    "# required orderwise tf uses up all the memory of GPU and crashes \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized\n",
    "    print(e)\n",
    "\n",
    "# getting the MNIST dataset : 60k of handwritten labelled digits \n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], n_input1, n_input1, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], n_input1, n_input1, 1)\n",
    "\n",
    "input_shape = (n_input1, n_input1, 1)\n",
    "\n",
    "# convert from integer to float\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# normalize to range 0-1\n",
    "\n",
    "x_train /= 255.0\n",
    "x_test /= 255.0\n",
    "\n",
    "# Building up the model \n",
    "\n",
    "model = keras.models.Sequential() \n",
    "\n",
    "model.add(keras.layers.Conv2D(n_input1,(n_kernel,n_kernel), activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\n",
    "model.add(keras.layers.MaxPooling2D(n_pool,n_pool))\n",
    "model.add(keras.layers.Conv2D(n_input2,(n_kernel,n_kernel),activation= 'relu', kernel_initializer='he_uniform'))\n",
    "model.add(keras.layers.Conv2D(n_input2,(n_kernel,n_kernel),activation='relu', kernel_initializer='he_uniform'))       \n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(n_pool,n_pool)))  \n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(100,activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(keras.layers.Dropout(0.2)) # avoid overfitting \n",
    "model.add(keras.layers.Dense(n_output, activation='softmax'))\n",
    "\n",
    "# Setting the optimizer and the loss function hyperparameters\n",
    "\n",
    "opt = keras.optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "model.compile (optimizer=opt,\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# training of the model on the GPU\n",
    "\n",
    "model.fit(x=x_train,y=y_train, batch_size=n_batch_size, epochs=n_epochs)\n",
    "\n",
    "# evaluation of the model \n",
    "\n",
    "model.evaluate(x_test, y_test)\n",
    "\n",
    "# save the model \n",
    "\n",
    "model.save('handwritten_digit_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x139D87AAF60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'prediction '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the model\n",
    "\n",
    "model = keras.models.load_model('handwritten_digit_model.h5')\n",
    "\n",
    "# load the example image \n",
    "\n",
    "filename = \"digit.png\" # put your image including file extension\n",
    "image = keras.preprocessing.image.load_img(filename,color_mode='grayscale', target_size=(n_input1,n_input1))\n",
    "\n",
    "display(\"image: \", image)\n",
    "\n",
    "#convert to array \n",
    "\n",
    "image = keras.preprocessing.image.img_to_array(image)\n",
    "\n",
    "#reshape into a single sample with 1 channel\n",
    "\n",
    "image = image.reshape(1,n_input1,n_input1,1)\n",
    "\n",
    "#prepare pixel data\n",
    "\n",
    "image = image.astype('float32')\n",
    "image = image / 255.0\n",
    "\n",
    "#predict the digit \n",
    "\n",
    "digit = model.predict_classes(image)\n",
    "display(\"prediction \", digit[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
